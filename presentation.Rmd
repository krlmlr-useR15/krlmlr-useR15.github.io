---
title: "Improving computational performance with algorithm engineering"
author: "Kirill Müller"
date: "July 1, 2015"
output: ioslides_presentation
---

```{r echo=FALSE}
library(mangow)
library(cluster)
library(magrittr)
library(ggplot2)
set.seed(20150619L)
knitr::opts_chunk$set(cache = TRUE, comment = "")

knit_print.dissimilarity <- function(x, options) {
  print(structure(x, class = "dist"))
}

knit_print.function <- function(x, options) {
  dput(x)
}
```

## Algorithm engineering

> Design, analysis, implementation, optimization, profiling and experimental evaluation of computer algorithms. (*Wikipedia*)

Here: Substitute existing implementation by an algorithm
with a lower computational complexity.


## Application

Generation of input for agent-based microsimulation models

- Input: register data, demographic and mobility surveys
- *Survey calibration*: Compute weights
- *Sampling without replacement*: Transform to integer weights
- *Statistical matching*: Combine datasets


## Overview

1. Weighted random sampling without replacement
2. Similarity-based statistical matching
3. Survey calibration


# Weighted random sampling without replacement

## Random sampling

```{r}
sample.int
```

- `n`: Number of items to choose from
- `size`: Number of items to choose
    - optimize for `size` ≫ `1`
- `replace`: With or without replacement
- `prob`: Uniform or non-uniform probabilities


## Implementation of random sampling

Common framework:

- Subdivide an interval according to probabilities
- Repeat
    - Uniformly sample point from interval
    - Choose sub-interval covered by point
    - If sampling without replacement, remove sub-interval

```{r echo=F}
interval_fig_height <- 0.6
ggplot_interval_base <-
  list(
    theme_classic(),
    theme(text = element_blank(), axis.line = element_blank(),
          axis.ticks = element_blank()),
    scale_color_identity(),
    theme(plot.margin = grid::unit(c(0,0,0,0), "line")),
    NULL
  )
ggplot_interval <-
  c(
    ggplot_interval_base,
    list(
      coord_flip(),
      NULL
    )
  )
ggplot_rainbow <-
  list(
    scale_fill_gradientn(colours = rainbow(23), guide = FALSE),
    NULL
  )
ggplot_interval_rainbow <-
  c(
    ggplot_interval,
    ggplot_rainbow
  )
```



## Implementation of random sampling

Common framework:

- **Subdivide an interval according to probabilities**
- Repeat
    - Uniformly sample point from interval
    - Choose sub-interval covered by point
    - If sampling without replacement, remove sub-interval

```{r echo=FALSE, fig.height=interval_fig_height}
N <- 10
prob <- prop.table(runif(N))
d <- data.frame(y=prob, yy=1/N)
ggplot(d, aes(x=0, y=y, group=0)) +
  ggplot_interval +
  geom_bar(position="stack", stat="identity", fill=NA, color="black")
```




## Implementation of random sampling

Common framework:

- Subdivide an interval according to probabilities
- Repeat
    - **Uniformly sample point from interval**
    - Choose sub-interval covered by point
    - If sampling without replacement, remove sub-interval

```{r echo=FALSE, fig.height=interval_fig_height}
yr <- runif(1)
d$r <- c(0, diff(cumsum(d$y) < yr))
ggplot(d, aes(x=0, y=y, group=0)) +
  ggplot_interval +
  geom_bar(position="stack", stat="identity", fill=NA, color="black") +
  geom_point(x=0, y=yr, color = "red")
```



## Implementation of random sampling

Common framework:

- Subdivide an interval according to probabilities
- Repeat
    - Uniformly sample point from interval
    - **Choose sub-interval covered by point**
    - If sampling without replacement, remove sub-interval

```{r echo=FALSE, fig.height=interval_fig_height}
ggplot(d, aes(x=0, y=y, group=0)) +
  ggplot_interval +
  geom_bar(aes(fill=ifelse(r, "green", NA)), position="stack", stat="identity", color=NA) +
  geom_bar(position="stack", stat="identity", fill=NA, color="black") +
  scale_fill_identity() +
  geom_point(x=0, y=yr, color = "red")
```


## Random sampling with replacement

- No need to remove sub-interval
- Uniform probabilities: No need for explicit interval

```{r echo=FALSE, fig.height=interval_fig_height}
ggplot(d, aes(x=0, y=yy, group=0)) +
  ggplot_interval +
  geom_bar(position="stack", stat="identity", fill=NA, color="black") +
  scale_fill_identity()
```

- Nonuniform probabilities: Binary search?
    - Better: Walker's alias method
    - Used in R if many elements are not entirely unlikely


```{r echo=FALSE, fig.height=interval_fig_height}
d$f <- seq_along(d$r)
ggplot(d, aes(x=0, y=y, group=0, fill=f)) +
  ggplot_interval_rainbow +
  geom_bar(position="stack", stat="identity", color="black")
```

```{r echo=FALSE, fig.height=interval_fig_height*2}
ggplot(d, aes(x=-order(y), y=y, group=f, fill=f)) +
  ggplot_interval_base +
  ggplot_rainbow +
  geom_bar(stat="identity", color="black") +
  geom_bar(aes(y=yy), position="stack", stat="identity", fill=NA, color="black", linetype=3)
```


## Implementation of random sampling

Common framework:

- Subdivide an interval according to probabilities
- Repeat
    - Uniformly sample point from interval
    - Choose sub-interval covered by point
    - **If sampling without replacement, remove sub-interval**

```{r echo=FALSE, fig.height=interval_fig_height}
ggplot(d, aes(x=0, y=y, group=0, fill=ifelse(r, NA, f))) +
  ggplot_interval_rainbow +
  geom_bar(position="stack", stat="identity", color="black")
```


```{r echo=FALSE, fig.height=interval_fig_height}
ggplot(d[!d$r,], aes(x=0, y=y, group=0, fill=f)) +
  ggplot_interval_rainbow +
  geom_bar(position="stack", stat="identity", color="black")
```


## Random sampling w/o replacement

Challenge: Remove sub-interval after each draw

Uniform probabilities: Rearrange array in $O(1)$

```{r echo=FALSE, fig.height=interval_fig_height}
ggplot(d, aes(x=0, y=yy, group=0, fill=ifelse(r, NA, f))) +
  ggplot_interval +
  ggplot_rainbow +
  geom_bar(position="stack", stat="identity", color="black")
```

```{r echo=FALSE, fig.height=interval_fig_height}
ggplot(head(d, -1), aes(x=0, y=yy, group=0, fill=ifelse(r, tail(d$f, 1), f))) +
  ggplot_interval +
  ggplot_rainbow +
  scale_y_continuous(limits = c(0,1)) +
  geom_bar(position="stack", stat="identity", color="black")
```

Nonuniform probabilities:

- R uses trivial algorithm with update in $O(n)$
- Heap-like data structure (Partial Sum Trees) with update in $O(\log n)$ (Wong and Easton, 1980)
- **Alternative approaches**


## Alternative approaches

- Rejection sampling
    - Sample with replacement, throw away duplicates
- One-pass sampling (Efraimidis and Spirakis, 2006)

```{r}
wrswoR::sample_int_rank
```

```r
n %>% rexp %>% divide_by(prob) %>%
  sort(index.return = TRUE) %>% use_series(ix) %>% head(size)
```


## Reservoir sampling

- $i \in {1, \ldots n}$
- $w_i > 0$
- $U_i$ independent uniform random variables

The probability that $X_i = (U_i)^{1 / w_i}$ is ordered in descending order
(i.e., $X_1 \geq X_2 \geq \ldots \geq X_n$) is equal to the probability
that the items are drawn in order (first $w_1$, then $w_2$, etc.)
in a weighted sampling without replacement.

- Use logarithm of $X_i$ for better numerical stability:

$$\log X_i = \log U_i \cdot \frac{1}{w_i} = \frac{-\text{Exp}_i(1)}{w_i} ⩮ \frac{w_i}{\text{Exp}_i(1)}$$


## Run time for different distributions



## Run time for different rates



## Linear model?



## Correctness



## Summary





# Similarity-based statistical matching

## Statistical matching (data fusion)

- Input: two joint distributions $(X, Y)$ and $(X, Z)$
- Output: a joint distribution $(X, Y, Z)$

**Hot deck**: Combine observations from $(X, Y)$ 
with "matching" observations from $(X, Z)$
to create a realization of $(X, Y, Z)$.

$$(x, y) ⋈ (x', z) = (x, y, z)$$

- Precondition: $Y$ and $Z$ independent given $X$

- Variants:
    - Exact: $x = x'$
    - **Approximate**: $x$ similar to $x'$


## Approximate hot-deck statistical matching

- Input: two samples from $(X, Y)$ and $(X, Z)$
- Output: a dataset $(X, Y, Z)$

For each $(x, y)$ in $(X, Y)$, randomly select $(x', z)$ from $(X, Z)$
so that $x$ similar to $x'$

- Similarity measure
    - Gower's distance
- Find $(x', z)$ for given $x$
    - $k$ nearest neighbors

## Gower's distance

Distance metric for multivariate distributions (Gower, 1971)

Weighted sum of distances for each variable, in $[0, 1]$

- Interval-scaled: Relative to interval width
- Ordinal variables: Relative to number of levels
- Nominal variables: 0 if equal, 1 otherwise

```{r data_def, echo=F}
data_int <- data.frame(int=c(1, 3, 6))
data_ord <- data.frame(ord = factor(letters[1:3], ordered = TRUE))
data_nm2 <- data.frame(nm2 = factor(LETTERS[c(1,2,2)]))
data_nm3 <- data.frame(nm3 = factor(LETTERS[3:5]))
```

```{r data_cbind_def, dependson="data_def"}
(data <- cbind(data_int, data_ord, data_nm2, data_nm3))
```


## From Gower's to Manhattan distance

<div class="columns-2">
```{r dependson="data_def"}
data_int
daisy(data_int, "gower")
(6 - 3) / 5
```

```{r dependson="data_def"}
(mdata_int <- mangow(data_int))
daisy(mdata_int, "manhattan")
```

Distance between second and third observation
</div>


## From Gower's to Manhattan distance

<div class="columns-2">
```{r dependson="data_def"}
data_ord
daisy(data_ord, "gower")
(3 - 2) / 2
```

```{r dependson="data_def"}
(mdata_ord <- mangow(data_ord))
daisy(mdata_ord, "manhattan")
```

Distance between second and third observation
</div>


## From Gower's to Manhattan distance

<div class="columns-2">
```{r dependson="data_def"}
data_nm2
daisy(data_nm2, "gower")
ifelse("B" == "B", 0, 1)
```

```{r dependson="data_def"}
(mdata_nm2 <- mangow(data_nm2))
daisy(mdata_nm2, "manhattan")
```

Distance between second and third observation
</div>


## From Gower's to Manhattan distance

<div class="columns-2">
```{r dependson="data_def"}
data_nm3
daisy(data_nm3, "gower")
ifelse("D" == "E", 0, 1)
```

```{r dependson="data_def"}
(mdata_nm3 <- mangow(data_nm3))
daisy(mdata_nm3, "manhattan")
```

Distance between second and third observation
</div>


## From Gower's to Manhattan distance

<div class="columns-2">
```{r dependson="data_cbind_def"}
data
daisy(data, "gower")
(0.6 + 0.5 + 0 + 1) / 4
```

```{r dependson="data_cbind_def"}
(mdata <- mangow(data))
daisy(mdata, "manhattan")
```

Distance between second and third observation
</div>


## Run time improvements

- Statistical matching with $8 \times 10^6$ recipients
  vs. $5 \times 10^4$ donors
    - Naïve approach: 20 hours
        - Compute all-pairs distances
    - Transform the problem: 20 minutes
        - Gower's -> Manhattan
        - 4 -> 6 columns
        - Use `RANN.L1` for finding the $k$ nearest donors
          for each recipient


## Summary



## Survey calibration



## Straightforward implementation



## Suggested implementation



## Performance comparison



## Summary



## Conclusion
